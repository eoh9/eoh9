# Reliability Analysis Pro - ê¸°ìˆ  ë©´ì ‘ ëŒ€ë¹„ìš© ìƒì„¸ ë³´ê³ ì„œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

**Reliability Analysis Pro v2.0**ëŠ” Excel MCP(Model Context Protocol)ë¥¼ í™œìš©í•œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ë° ì‹ ë¢°ì„± ë¶„ì„ í”Œë«í¼ì…ë‹ˆë‹¤. 100ë§Œ+ í–‰ì˜ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ , ì „ë¬¸ì ì¸ Excel ë¦¬í¬íŠ¸ì™€ ì°¨íŠ¸ë¥¼ ìë™ ìƒì„±í•˜ëŠ” ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

### ğŸ¯ **ì™œ ì´ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ì—ˆë‚˜ìš”?**

#### **1. ê¸°ì¡´ ë¬¸ì œì **
- **ìˆ˜ë™ ë¶„ì„ì˜ í•œê³„**: ì—”ì§€ë‹ˆì–´ë“¤ì´ Excelì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ì°¨íŠ¸ë¥¼ ê·¸ë¦¬ê³ , í†µê³„ë¥¼ ê³„ì‚°í•˜ëŠ”ë° í•˜ë£¨ ì¢…ì¼ ì†Œìš”
- **ë°ì´í„° í¬ê¸° ì œì•½**: 100ë§Œ í–‰ ì´ìƒì˜ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ Excelì´ ë©ˆì¶”ê±°ë‚˜ ë§¤ìš° ëŠë ¤ì§
- **ì¼ê´€ì„± ë¶€ì¡±**: ì‚¬ëŒë§ˆë‹¤ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ê²°ê³¼ì˜ ì¼ê´€ì„±ê³¼ ì‹ ë¢°ì„± ë¶€ì¡±
- **ë°˜ë³µ ì‘ì—…**: ë¹„ìŠ·í•œ ë¶„ì„ì„ ë§¤ë²ˆ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ” ë¹„íš¨ìœ¨ì„±

#### **2. í•´ê²°í•˜ê³  ì‹¶ì€ ê²ƒ**
- **ìë™í™”**: ë°ì´í„° ì—…ë¡œë“œ â†’ ë¶„ì„ â†’ ë¦¬í¬íŠ¸ ìƒì„±ê¹Œì§€ ì „ ê³¼ì • ìë™í™”
- **ëŒ€ìš©ëŸ‰ ì²˜ë¦¬**: 100ë§Œ+ í–‰ ë°ì´í„°ë¥¼ ë¹ ë¥´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬
- **ì „ë¬¸ì„±**: í†µê³„ì ìœ¼ë¡œ ê²€ì¦ëœ ë°©ë²•ë¡ ìœ¼ë¡œ ì •í™•í•œ ì‹ ë¢°ì„± ë¶„ì„
- **ì¬ì‚¬ìš©ì„±**: í•œ ë²ˆ ë§Œë“  ë¶„ì„ ëª¨ë¸ì„ ë‹¤ë¥¸ ì œí’ˆì—ë„ ì ìš© ê°€ëŠ¥

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1. ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   Excel MCP     â”‚
â”‚   (HTML/JS)     â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚   Services      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ íŒŒì¼ ì—…ë¡œë“œ    â”‚    â”‚ â€¢ API ì—”ë“œí¬ì¸íŠ¸  â”‚    â”‚ â€¢ ëŒ€ìš©ëŸ‰ ë°ì´í„°  â”‚
â”‚ â€¢ ì§„í–‰ìƒí™© í‘œì‹œ  â”‚    â”‚ â€¢ ë¹„ë™ê¸° ì²˜ë¦¬    â”‚    â”‚   ì²˜ë¦¬          â”‚
â”‚ â€¢ ê²°ê³¼ ì‹œê°í™”    â”‚    â”‚ â€¢ ì„œë¹„ìŠ¤ ë ˆì´ì–´  â”‚    â”‚ â€¢ Excel ìƒì„±    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. ë°±ì—”ë“œ ì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜
```
FastAPI Application
â”œâ”€â”€ Main Router (/)
â”œâ”€â”€ File Upload (/upload)
â”œâ”€â”€ Beta Search (/search_beta)
â”œâ”€â”€ Analysis (/analyze)
â”œâ”€â”€ Excel MCP Endpoints
â”‚   â”œâ”€â”€ /excel/process_large_dataset
â”‚   â”œâ”€â”€ /excel/generate_analysis_report
â”‚   â”œâ”€â”€ /excel/optimize_large_dataset
â”‚   â””â”€â”€ /excel/get_chart_instructions
â””â”€â”€ Health & Stats (/health, /stats)
```

## ğŸ”§ í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ

### 1. ë°±ì—”ë“œ ê¸°ìˆ 
- **FastAPI 0.115.13**: ë¹„ë™ê¸° ì›¹ í”„ë ˆì„ì›Œí¬, ìë™ API ë¬¸ì„œí™”
- **Pandas 2.3.0**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„
- **NumPy 2.3.0**: ìˆ˜ì¹˜ ê³„ì‚° ë° í†µê³„ ë¶„ì„
- **OpenAI API 1.88.0**: AI ê¸°ë°˜ ë² íƒ€ ê°’ ê²€ìƒ‰ ë° ë¶„ì„
- **Uvicorn 0.34.3**: ASGI ì„œë²„

### 2. **ì™œ ì´ ê¸°ìˆ ë“¤ì„ ì„ íƒí–ˆë‚˜ìš”?**

#### **FastAPIë¥¼ ì„ íƒí•œ ì´ìœ **
```python
# ê¸°ì¡´ Flask vs FastAPI ë¹„êµ
# Flask (ë™ê¸°ì‹)
@app.route('/analyze', methods=['POST'])
def analyze_data():
    # 100ë§Œ í–‰ ë°ì´í„° ì²˜ë¦¬ ì¤‘...
    # ì´ ì‹œê°„ ë™ì•ˆ ë‹¤ë¥¸ ìš”ì²­ì€ ëŒ€ê¸°í•´ì•¼ í•¨
    result = process_large_dataset(data)  # 30ì´ˆ ì†Œìš”
    return result

# FastAPI (ë¹„ë™ê¸°ì‹)
@app.post("/analyze")
async def analyze_data():
    # ì¦‰ì‹œ job_id ë°˜í™˜
    job_id = str(uuid.uuid4())
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ (ë‹¤ë¥¸ ìš”ì²­ ì²˜ë¦¬ ê°€ëŠ¥)
    background_tasks.add_task(run_analysis_job, job_id, data)
    
    return {"job_id": job_id, "status": "started"}
```

**ì¥ì :**
- **ë™ì‹œ ì²˜ë¦¬**: 100ë§Œ í–‰ ë°ì´í„° ë¶„ì„ ì¤‘ì—ë„ ë‹¤ë¥¸ ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬ ê°€ëŠ¥
- **ìë™ ë¬¸ì„œí™”**: `/docs`ì—ì„œ API ì‚¬ìš©ë²• ìë™ ìƒì„±
- **íƒ€ì… ì•ˆì „ì„±**: Python íƒ€ì… íŒíŠ¸ë¡œ ëŸ°íƒ€ì„ ì—ëŸ¬ ë°©ì§€
- **ì„±ëŠ¥**: Node.jsë‚˜ Goì— ê·¼ì ‘í•œ ì†ë„

#### **Pandas + NumPyë¥¼ ì„ íƒí•œ ì´ìœ **
```python
# ê¸°ì¡´ ë°©ë²• (ìˆœìˆ˜ Python)
def calculate_statistics_old(data):
    total = 0
    count = 0
    for item in data:  # 100ë§Œ ë²ˆ ë°˜ë³µ
        total += item['usage']
        count += 1
    mean = total / count  # ë§¤ìš° ëŠë¦¼
    
# Pandas + NumPy ì‚¬ìš©
def calculate_statistics_new(data):
    df = pd.DataFrame(data)
    # C ë ˆë²¨ì—ì„œ ìµœì í™”ëœ ì—°ì‚° (100ë°° ë¹ ë¦„)
    mean = df['usage'].mean()
    median = df['usage'].median()
    std = df['usage'].std()
```

**ì¥ì :**
- **ì†ë„**: C ì–¸ì–´ë¡œ êµ¬í˜„ëœ ë‚´ë¶€ ì—°ì‚°ìœ¼ë¡œ ìˆœìˆ˜ Python ëŒ€ë¹„ 100ë°° ë¹ ë¦„
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬
- **í†µê³„ í•¨ìˆ˜**: 1000+ ê°œì˜ í†µê³„ í•¨ìˆ˜ ì œê³µ
- **ë°ì´í„° ë³€í™˜**: Excel, CSV ë“± ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›

### 2. Excel MCP ê¸°ìˆ 
- **Excel MCP Processor**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²­í‚¹ ì²˜ë¦¬
- **Excel Chart Generator**: ì „ë¬¸ì ì¸ ì°¨íŠ¸ ë° í…Œì´ë¸” ìƒì„±
- **Chunked Processing**: 10ë§Œ í–‰ ë‹¨ìœ„ ë©”ëª¨ë¦¬ ìµœì í™”
- **Multi-sheet Workbooks**: 7ê°œ ì‹œíŠ¸ êµ¬ì¡°í™”ëœ ë¦¬í¬íŠ¸

#### **Excel MCPë¥¼ ì„ íƒí•œ ì´ìœ **

**ê¸°ì¡´ ë¬¸ì œì :**
```python
# ê¸°ì¡´ ë°©ë²•: ëª¨ë“  ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
def process_data_old(data):
    df = pd.read_excel("large_file.xlsx")  # 100ë§Œ í–‰
    # ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ í”„ë¡œê·¸ë¨ í¬ë˜ì‹œ!
    # ë˜ëŠ” ë§¤ìš° ëŠë¦° ì²˜ë¦¬ ì†ë„
    return df.describe()
```

**Excel MCP í•´ê²°ì±…:**
```python
# Excel MCP: ì²­í‚¹ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
def process_data_new(data):
    chunks = []
    chunk_size = 100000  # 10ë§Œ í–‰ì”©
    
    for i in range(0, len(data), chunk_size):
        chunk = data[i:i + chunk_size]
        # ê° ì²­í¬ë¥¼ ë…ë¦½ì ì¸ Excel íŒŒì¼ë¡œ ìƒì„±
        chunk_file = create_excel_chunk(chunk, f"chunk_{i//chunk_size}")
        chunks.append(chunk_file)
    
    # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì´ê³  ë¹ ë¥¸ ì²˜ë¦¬
    return process_chunks(chunks)
```

**ì™œ 10ë§Œ í–‰ì¸ê°€ìš”?**
- **ë©”ëª¨ë¦¬ ì œí•œ**: ì¼ë°˜ì ì¸ ì»´í“¨í„°ì˜ ë©”ëª¨ë¦¬ í•œê³„ë¥¼ ê³ ë ¤
- **Excel ì„±ëŠ¥**: Excelì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ í–‰ ìˆ˜
- **ì²˜ë¦¬ ì†ë„**: ì²­í¬ë³„ë¡œ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
- **ì‚¬ìš©ì ê²½í—˜**: íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í¬ë©´ ì—´ê¸°/ì €ì¥ì´ ëŠë ¤ì§

### 3. í”„ë¡ íŠ¸ì—”ë“œ ê¸°ìˆ 
- **HTML5 + CSS3**: ë°˜ì‘í˜• ì›¹ ë””ìì¸
- **Bootstrap 5.3.2**: ëª¨ë˜ UI ì»´í¬ë„ŒíŠ¸
- **Vanilla JavaScript**: ES6+ ë¹„ë™ê¸° ì²˜ë¦¬
- **Real-time Progress**: í´ë§ ê¸°ë°˜ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸

## ğŸ“Š Excel MCP ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ

### 1. ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

#### 1.1 ì²­í‚¹ ì „ëµ (Chunking Strategy)
```python
class ExcelMCPProcessor:
    def __init__(self):
        self.chunk_size = 100000  # 10ë§Œ í–‰ì”© ì²˜ë¦¬
        self.max_rows_for_charts = 10000  # ì°¨íŠ¸ìš© ìµœëŒ€ í–‰ ìˆ˜
```

**ì²­í‚¹ ì•Œê³ ë¦¬ì¦˜:**
- ë°ì´í„°ë¥¼ 10ë§Œ í–‰ ë‹¨ìœ„ë¡œ ë¶„í• 
- ê° ì²­í¬ë³„ë¡œ ë…ë¦½ì ì¸ Excel íŒŒì¼ ìƒì„±
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ 100MB ì´í•˜ë¡œ ì œí•œ
- ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ êµ¬ì¡°

#### 1.2 ë©”ëª¨ë¦¬ ìµœì í™” ê¸°ë²•
```python
def _identify_data_quality_issues(self, df: pd.DataFrame):
    # ê²°ì¸¡ì¹˜ ë¬¸ì œ ì‹ë³„ (10% ì´ìƒ)
    # ì¤‘ë³µ ë°ì´í„° ë¬¸ì œ ì‹ë³„ (10% ì´ìƒ)
    # ì´ìƒì¹˜ ë¬¸ì œ ì‹ë³„ (IQR ê¸°ë°˜, 5% ì´ìƒ)
    # ë°ì´í„° íƒ€ì… ìµœì í™” ê¶Œì¥ì‚¬í•­
```

**ìµœì í™” ì „ëµ:**
- `int64` â†’ `int8/int16` ë³€í™˜ (ë²”ìœ„ ê¸°ë°˜)
- `object` â†’ `category` ë³€í™˜ (ê³ ìœ ê°’ 50% ë¯¸ë§Œ)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ì²­í‚¹ í¬ê¸° ìë™ ì¡°ì •

#### 1.3 ì²­í‚¹ ì²˜ë¦¬ ë° Excel íŒŒì¼ ìƒì„±
```python
def _create_chunked_excel_files(self, data: List[Dict[str, Any]], 
                               filename: str) -> List[Path]:
    """ë°ì´í„°ë¥¼ ì²­í¬ë³„ë¡œ ë‚˜ëˆ„ì–´ Excel íŒŒì¼ ìƒì„±"""
    excel_files = []
    
    # ë°ì´í„°ë¥¼ ì²­í¬ë¡œ ë¶„í•  (10ë§Œ í–‰ ë‹¨ìœ„)
    chunks = [data[i:i + self.chunk_size] 
             for i in range(0, len(data), self.chunk_size)]
    
    for i, chunk in enumerate(chunks):
        chunk_filename = f"{Path(filename).stem}_chunk_{i+1:03d}.xlsx"
        chunk_path = Path(self.temp_dir) / chunk_filename
        
        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ Excel íŒŒì¼ ìƒì„±
        df_chunk = pd.DataFrame(chunk)
        df_chunk.to_excel(chunk_path, index=False, engine='openpyxl')
        excel_files.append(chunk_path)
    
    return excel_files
```

**ì²­í‚¹ ì²˜ë¦¬ íŠ¹ì§•:**
- **ì²­í¬ í¬ê¸°**: 10ë§Œ í–‰ ë‹¨ìœ„ë¡œ ë¶„í• 
- **íŒŒì¼ ëª…ëª…**: `filename_chunk_001.xlsx` í˜•ì‹
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ê° ì²­í¬ë³„ë¡œ ë…ë¦½ì ì¸ Excel íŒŒì¼ ìƒì„±
- **ë³‘ë ¬ ì²˜ë¦¬**: ì²­í¬ë³„ë¡œ ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥í•œ êµ¬ì¡°

### 2. ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œ

#### 2.1 ìë™ í’ˆì§ˆ í‰ê°€
```python
def _calculate_quality_score(self, results: Dict[str, Any]) -> float:
    score = 100  # ê¸°ë³¸ ì ìˆ˜
    
    # ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì— ë”°ë¥¸ ê°ì  (ìµœëŒ€ 30ì )
    score -= min(missing_ratio * 2, 30)
    
    # í’ˆì§ˆ ë¬¸ì œ ê°œìˆ˜ì— ë”°ë¥¸ ê°ì 
    score -= high_severity * 10  # ê³ ì‹¬ê°ë„ ë¬¸ì œë‹¹ 10ì 
    score -= medium_severity * 5  # ì¤‘ê°„ì‹¬ê°ë„ ë¬¸ì œë‹¹ 5ì 
```

**í’ˆì§ˆ ì§€í‘œ:**
- ë°ì´í„° ì™„ì„±ë„ (ê²°ì¸¡ì¹˜ ë¹„ìœ¨)
- ë°ì´í„° ë¬´ê²°ì„± (ì¤‘ë³µ, ì´ìƒì¹˜)
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- ì²˜ë¦¬ ì„±ëŠ¥ (í–‰/ì´ˆ)

#### 2.2 ìë™ ê¶Œì¥ì‚¬í•­ ìƒì„±
```python
def _generate_data_quality_recommendations(self, df: pd.DataFrame):
    recommendations = []
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë°©ì•ˆ
    if missing_cols:
        recommendations.append(f"ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” {len(missing_cols)}ê°œ ì»¬ëŸ¼ì— ëŒ€í•œ ì²˜ë¦¬ ë°©ì•ˆ ìˆ˜ë¦½ í•„ìš”")
    
    # ë©”ëª¨ë¦¬ ìµœì í™” ë°©ì•ˆ
    if memory_usage > 100:
        recommendations.append("ëŒ€ìš©ëŸ‰ ë°ì´í„° ë©”ëª¨ë¦¬ ìµœì í™” (ë°ì´í„° íƒ€ì… ë³€í™˜, ì²­í‚¹ ì²˜ë¦¬)")
```

## ğŸ“ˆ Excel ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ

### 1. ë‹¤ì¤‘ ì‹œíŠ¸ ì›Œí¬ë¶ êµ¬ì¡°

#### 1.1 ì‹œíŠ¸ êµ¬ì„±
```
1. ìš”ì•½ëŒ€ì‹œë³´ë“œ: í•µì‹¬ KPI ë° ë¶„ì„ ê²°ê³¼ ìš”ì•½
2. ë°ì´í„°í’ˆì§ˆ: ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ë° ë¬¸ì œì 
3. ì‚¬ìš©í†µê³„: ê¸°ë³¸ í†µê³„ëŸ‰ ë° ë¶„í¬ ì •ë³´
4. Weibullë¶„ì„: ì‹ ë¢°ì„± ë¶„ì„ ë§¤ê°œë³€ìˆ˜
5. í…ŒìŠ¤íŠ¸ê³„íš: ì‹ ë¢°ì„± í…ŒìŠ¤íŠ¸ ê³„íš ë° ì‹œê°„
6. íˆìŠ¤í† ê·¸ë¨ë°ì´í„°: ì°¨íŠ¸ ìƒì„±ìš© ë°ì´í„°
7. ì‹ ë¢°ë„ê³¡ì„ : ì‹œê°„ì— ë”°ë¥¸ ì‹ ë¢°ë„ ë³€í™”
8. ë² íƒ€ê²€ìƒ‰ê²°ê³¼: ë² íƒ€ ê°’ ê²€ìƒ‰ ê²°ê³¼
9. ë¶„ì„ì„¤ì •: ë¶„ì„ ì„¤ì • ë° ë°©ë²•ë¡ 
10. ì‹œìŠ¤í…œì •ë³´: ê¸°ìˆ  ìŠ¤íƒ ë° ì„±ëŠ¥ ì •ë³´
```

#### 1.2 ì „ë¬¸ ì°¨íŠ¸ ìŠ¤íƒ€ì¼ë§ ì‹œìŠ¤í…œ
```python
def __init__(self):
    self.chart_styles = {
        'primary_color': '#6366f1',      # ì£¼ìš” ìƒ‰ìƒ
        'secondary_color': '#8b5cf6',    # ë³´ì¡° ìƒ‰ìƒ
        'success_color': '#10b981',      # ì„±ê³µ ìƒ‰ìƒ
        'warning_color': '#f59e0b',      # ê²½ê³  ìƒ‰ìƒ
        'danger_color': '#ef4444',       # ìœ„í—˜ ìƒ‰ìƒ
        'text_color': '#1f2937',         # í…ìŠ¤íŠ¸ ìƒ‰ìƒ
        'background_color': '#f8fafc'    # ë°°ê²½ ìƒ‰ìƒ
    }
```

**ì°¨íŠ¸ ìƒì„± íŠ¹ì§•:**
- **ì „ë¬¸ì ì¸ ìƒ‰ìƒ í…Œë§ˆ**: ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë³´ê³ ì„œìš© ìƒ‰ìƒ ì²´ê³„
- **ìë™ í¬ë§·íŒ…**: í…Œì´ë¸” í—¤ë”, ì…€ ìŠ¤íƒ€ì¼, í…Œë‘ë¦¬ ìë™ ì ìš©
- **ë°˜ì‘í˜• ë ˆì´ì•„ì›ƒ**: ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ìë™ ë ˆì´ì•„ì›ƒ ì¡°ì •
- **Excel MCP ìµœì í™”**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ì°¨íŠ¸ ìµœì í™”

### 2. ëŒ€ìš©ëŸ‰ ë°ì´í„° ê¸°ë°˜ ì‹ ë¢°ì„± í…ŒìŠ¤íŠ¸ ê³„ì‚°

#### 2.1 ìë™ Test Time ë„ì¶œ ì‹œìŠ¤í…œ
```python
class WeibullAnalyzer:
    def calculate_test_times(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ìœ¼ë¡œ test time ê³„ì‚°"""
        
        # 1ë‹¨ê³„: ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        validated_data = self._validate_large_dataset(data)
        
        # 2ë‹¨ê³„: Weibull ë§¤ê°œë³€ìˆ˜ ì¶”ì •
        weibull_params = self._estimate_weibull_parameters(validated_data)
        
        # 3ë‹¨ê³„: ì‹ ë¢°ë„ ëª©í‘œë³„ test time ê³„ì‚°
        test_times = []
        for reliability_target in [90, 95, 99, 99.9]:  # 90%, 95%, 99%, 99.9%
            test_time = self._calculate_test_time_for_reliability(
                weibull_params, 
                reliability_target,
                data['confidence_level']
            )
            test_times.append({
                'reliability_target': reliability_target,
                'test_time': test_time,
                'sample_size': self._calculate_optimal_sample_size(test_time, weibull_params),
                'confidence_interval': self._calculate_confidence_interval(test_time, weibull_params)
            })
        
        return test_times
```

#### 2.2 ë² íƒ€ ê°’ ìë™ ê²€ìƒ‰ ë° ê²€ì¦
```python
class BetaSearcher:
    def intelligent_beta_search(self, product_name: str, usage_data: List[float]) -> BetaSearchResult:
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§€ëŠ¥í˜• ë² íƒ€ ê°’ ê²€ìƒ‰"""
        
        # 1ë‹¨ê³„: ë°ì´í„° íŒ¨í„´ ë¶„ì„
        data_pattern = self._analyze_usage_pattern(usage_data)
        
        # 2ë‹¨ê³„: ë‹¤ì¤‘ ì†ŒìŠ¤ ë² íƒ€ ê°’ ê²€ìƒ‰
        beta_sources = []
        
        # ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
        db_result = self._search_local_database(product_name, data_pattern)
        if db_result:
            beta_sources.append(('database', db_result))
        
        # OpenAI API ê²€ìƒ‰ (ì œí’ˆ íŠ¹ì„± ê¸°ë°˜)
        ai_result = await self._search_with_openai(product_name, data_pattern)
        if db_result:
            beta_sources.append(('openai', ai_result))
        
        # ì›¹ ê²€ìƒ‰ (ìµœì‹  ê¸°ìˆ  ë¬¸ì„œ)
        web_result = await self._search_web_sources(product_name, data_pattern)
        if web_result:
            beta_sources.append(('web', web_result))
        
        # 3ë‹¨ê³„: ë² íƒ€ ê°’ í†µí•© ë° ê²€ì¦
        validated_beta = self._validate_and_integrate_beta_values(beta_sources, usage_data)
        
        return validated_beta
```

#### 2.3 39ê°œ ì»´í¬ë„ŒíŠ¸ ë² íƒ€ ë°ì´í„°ë² ì´ìŠ¤

**ì™œ ë² íƒ€ ê°’ì´ ì¤‘ìš”í•œê°€ìš”?**

**1. ë² íƒ€ ê°’ì˜ ë¬¼ë¦¬ì  ì˜ë¯¸:**
```python
# ë² íƒ€ ê°’ì— ë”°ë¥¸ ê³ ì¥ë¥  íŒ¨í„´
BETA_PATTERNS = {
    "beta < 1": "ì´ˆê¸° ê³ ì¥ë¥  ë†’ìŒ (infant mortality)",
    "beta = 1": "ê³ ì¥ë¥  ì¼ì • (ì§€ìˆ˜ë¶„í¬)",
    "beta > 1": "ê³ ì¥ë¥  ì¦ê°€ (ë…¸í™” í˜„ìƒ)",
    "beta = 2": "ì •ê·œë¶„í¬ì™€ ìœ ì‚¬",
    "beta = 3.4": "ì •ê·œë¶„í¬ì™€ ê±°ì˜ ë™ì¼"
}

# ì‹¤ì œ ì˜ˆì‹œ
# ëƒ‰ì¥ê³  (beta = 1.5): ì´ˆê¸° ê³ ì¥ë¥ ì´ ë†’ë‹¤ê°€ ì ì°¨ ì•ˆì •í™”
# ëª¨í„° (beta = 2.5): ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ê³ ì¥ë¥ ì´ ì¦ê°€ (ë§ˆëª¨ í˜„ìƒ)
# ì „ìë¶€í’ˆ (beta = 1.1): ê±°ì˜ ì¼ì •í•œ ê³ ì¥ë¥ 
```

**2. 39ê°œ ì»´í¬ë„ŒíŠ¸ë¥¼ ì„ íƒí•œ ì´ìœ :**
```python
BETA_DATABASE = {
    # ê°€ì „ì œí’ˆ (5ê°œ) - ì¼ë°˜ ê°€ì •ì—ì„œ ë§ì´ ì‚¬ìš©
    "refrigerator": {"beta": 1.5, "source": "IEC 60335 Standard", "confidence": "high"},
    "freezer": {"beta": 1.4, "source": "Appliance Reliability Handbook", "confidence": "high"},
    "washing_machine": {"beta": 2.0, "source": "Rotating Machinery Data", "confidence": "high"},
    "dryer": {"beta": 1.9, "source": "Heat Treatment Equipment", "confidence": "high"},
    "dishwasher": {"beta": 2.2, "source": "Water Treatment Equipment", "confidence": "high"},
    
    # ì „ìì œí’ˆ (5ê°œ) - ì „ì ì‚°ì—… í•µì‹¬ ì œí’ˆ
    "air_conditioner": {"beta": 1.8, "source": "HVAC System Analysis", "confidence": "high"},
    "microwave": {"beta": 1.3, "source": "Electronic Equipment Standard", "confidence": "high"},
    "oven": {"beta": 1.6, "source": "Heating Equipment Reliability", "confidence": "high"},
    "television": {"beta": 1.2, "source": "Display Equipment", "confidence": "medium"},
    "smartphone": {"beta": 1.1, "source": "Mobile Device Analysis", "confidence": "medium"},
    
    # ì»´í“¨í„° ì¥ë¹„ (3ê°œ) - IT ì‚°ì—…
    "laptop": {"beta": 1.3, "source": "Computer System", "confidence": "medium"},
    "motor": {"beta": 2.5, "source": "IEEE Industrial Standard", "confidence": "high"},
    "bearing": {"beta": 2.0, "source": "Mechanical Component Reliability", "confidence": "high"},
    
    # ì‚°ì—… ì¥ë¹„ (5ê°œ) - ì œì¡°ì—… í•µì‹¬ ì¥ë¹„
    "pump": {"beta": 2.3, "source": "Fluid Machinery Data", "confidence": "high"},
    "compressor": {"beta": 2.0, "source": "Component Database", "confidence": "medium"},
    "fan_motor": {"beta": 2.0, "source": "Component Database", "confidence": "medium"},
    "vacuum_cleaner": {"beta": 2.1, "source": "Motor Driven Equipment", "confidence": "high"},
    
    # ì „ì ë¶€í’ˆ (5ê°œ) - ì „ì ì‚°ì—… ê¸°ì´ˆ ë¶€í’ˆ
    "capacitor": {"beta": 2.8, "source": "Component Database", "confidence": "confidence": "medium"},
    "switch": {"beta": 1.5, "source": "Component Database", "confidence": "medium"},
    "valve": {"beta": 1.7, "source": "Component Database", "confidence": "medium"}
}
```

**3. ì‹ ë¢°ë„ ë“±ê¸‰ì˜ ì˜ë¯¸:**
- **High**: êµ­ì œ í‘œì¤€(IEC, IEEE) ë˜ëŠ” ê³µì‹ ë ¥ ìˆëŠ” ì—°êµ¬ ê¸°ê´€ ë°ì´í„°
- **Medium**: ì—…ê³„ í‘œì¤€ ë˜ëŠ” ê²€ì¦ëœ ë°ì´í„°ë² ì´ìŠ¤
- **Low**: ì¶”ì •ì¹˜ ë˜ëŠ” ì œí•œì ì¸ ë°ì´í„° (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

**ë² íƒ€ ê°’ ê²€ìƒ‰ íŠ¹ì§•:**
- **39ê°œ ì»´í¬ë„ŒíŠ¸**: ì‹¤ì œ ì‚°ì—… í‘œì¤€ ë° ì—°êµ¬ ë°ì´í„° ê¸°ë°˜
- **ì‹ ë¢°ë„ ë“±ê¸‰**: high/medium ì‹ ë¢°ë„ë¡œ ë°ì´í„° í’ˆì§ˆ êµ¬ë¶„
- **ì¶œì²˜ ëª…ì‹œ**: IEC, IEEE, ì‚°ì—… í‘œì¤€ ë“± ê³µì‹ ë ¥ ìˆëŠ” ì¶œì²˜
- **ìë™ ê²€ìƒ‰**: ì œí’ˆëª… ì…ë ¥ ì‹œ ê°€ì¥ ì í•©í•œ ë² íƒ€ ê°’ ìë™ ì¶”ì²œ

#### 2.3 ì‹ ë¢°ì„± í…ŒìŠ¤íŠ¸ ìë™ ê³„ì‚°
```python
def _calculate_comprehensive_reliability_metrics(self, data: Dict[str, Any]) -> Dict[str, Any]:
    """ëŒ€ìš©ëŸ‰ ë°ì´í„° ê¸°ë°˜ ì¢…í•© ì‹ ë¢°ì„± ì§€í‘œ ê³„ì‚°"""
    
    # 1ë‹¨ê³„: ê¸°ë³¸ í†µê³„ëŸ‰ ê³„ì‚°
    basic_stats = self._calculate_basic_statistics(data['usage_data'])
    
    # 2ë‹¨ê³„: Weibull ë¶„í¬ ì í•©ë„ ê²€ì •
    weibull_goodness_of_fit = self._perform_weibull_goodness_of_fit_test(data['usage_data'])
    
    # 3ë‹¨ê³„: ì‹ ë¢°ë„ ê³¡ì„  ìƒì„±
    reliability_curve = self._generate_reliability_curve(
        data['weibull_params'],
        time_range=[0, data['max_usage_time'] * 1.5]
    )
    
    # 4ë‹¨ê³„: ìˆ˜ëª… ì˜ˆì¸¡ ëª¨ë¸
    lifetime_prediction = self._predict_lifetime_distribution(
        data['weibull_params'],
        confidence_level=data['confidence_level']
    )
    
    # 5ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ê³„íš ìµœì í™”
    optimal_test_plan = self._optimize_test_plan(
        data['reliability_target'],
        data['confidence_level'],
        data['weibull_params']
    )
    
    return {
        'basic_statistics': basic_stats,
        'weibull_goodness_of_fit': weibull_goodness_of_fit,
        'reliability_curve': reliability_curve,
        'lifetime_prediction': lifetime_prediction,
        'optimal_test_plan': optimal_test_plan,
        'data_quality_score': self._calculate_data_quality_score(data)
    }
```

#### 2.4 Weibull Test Time ê³„ì‚° ê³µì‹

**ì™œ Weibull ë¶„í¬ë¥¼ ì‚¬ìš©í•˜ë‚˜ìš”?**

**1. ì‹ ë¢°ì„± ê³µí•™ì—ì„œì˜ ì¤‘ìš”ì„±:**
- **ì œí’ˆ ìˆ˜ëª… ë¶„í¬**: ëŒ€ë¶€ë¶„ì˜ ì œí’ˆì´ Weibull ë¶„í¬ë¥¼ ë”°ë¦„
- **ê³ ì¥ë¥  ë³€í™”**: ì´ˆê¸° ê³ ì¥ë¥ (infant mortality) â†’ ì •ìƒ ê³ ì¥ë¥  â†’ ë…¸í™” ê³ ì¥ë¥ (wear-out)
- **ìœ ì—°ì„±**: ì§€ìˆ˜ë¶„í¬, ì •ê·œë¶„í¬ ë“± ë‹¤ì–‘í•œ ë¶„í¬ë¥¼ í¬í•¨

**2. ìˆ˜í•™ì  ê³µì‹ì˜ ì˜ë¯¸:**
```python
def _calculate_single_test_time(self, F2: float, N: int, reliability_target: float,
                              confidence_level: float, beta: float) -> float:
    """
    Weibull ë¶„í¬ ê¸°ë°˜ ì •í™•í•œ í…ŒìŠ¤íŠ¸ ì‹œê°„ ê³„ì‚°
    
    ê³µì‹: Test_Time = F2 * (-ln(R) / ln(CL))^(1/beta) / N^(0.5)
    
    ê° ë¶€ë¶„ì˜ ì˜ë¯¸:
    - F2: ì¤‘ìœ„ ìˆ˜ëª… (50% ì œí’ˆì´ ê³ ì¥ë‚˜ëŠ” ì‹œê°„)
    - (-ln(R)): ì‹ ë¢°ë„ ëª©í‘œì— ë”°ë¥¸ ê³ ì¥ í™•ë¥ 
    - ln(CL): ì‹ ë¢° ìˆ˜ì¤€ (í†µê³„ì  í™•ì‹¤ì„±)
    - 1/beta: Weibull í˜•ìƒ ë§¤ê°œë³€ìˆ˜ì˜ ì˜í–¥
    - 1/âˆšN: ìƒ˜í”Œ í¬ê¸° íš¨ê³¼ (í° ìƒ˜í”Œ = ì ì€ í…ŒìŠ¤íŠ¸ ì‹œê°„)
    """
    
    # ì‹¤ì œ ì˜ˆì‹œë¡œ ì„¤ëª…
    # ì œí’ˆ: ëƒ‰ì¥ê³ , ì¤‘ìœ„ìˆ˜ëª…: 10ë…„, ì‹ ë¢°ë„: 95%, ì‹ ë¢°ìˆ˜ì¤€: 90%, ë² íƒ€: 1.5
    # Test_Time = 10 * (-ln(0.95) / ln(0.9))^(1/1.5) / âˆš5 = 3.2ë…„
    
    # ì´ëŠ” "5ê°œ ëƒ‰ì¥ê³ ë¥¼ 3.2ë…„ í…ŒìŠ¤íŠ¸í•˜ë©´ 95% ì‹ ë¢°ë„ë¡œ 10ë…„ ìˆ˜ëª…ì„ ë³´ì¥í•  ìˆ˜ ìˆë‹¤"ëŠ” ì˜ë¯¸
```
    try:
        if F2 <= 0 or N <= 0:
            return 0
            
        # ê³ ì¥ í™•ë¥  ë° ì‹ ë¢°ë„ ê³„ìˆ˜ ê³„ì‚°
        failure_prob = 1 - reliability_target  # (1 - R)
        confidence_factor = -math.log(confidence_level)  # -ln(CL)
        
        # Weibull ê°€ì† ê³„ìˆ˜
        weibull_factor = (confidence_factor / (-math.log(failure_prob))) ** (1/beta)
        
        # ìƒ˜í”Œ í¬ê¸° íš¨ê³¼ (í° ìƒ˜í”Œì€ ì ì€ í…ŒìŠ¤íŠ¸ ì‹œê°„ í•„ìš”)
        sample_factor = 1 / math.sqrt(N)
        
        # í…ŒìŠ¤íŠ¸ ì‹œê°„ ê³„ì‚°
        test_time = F2 * weibull_factor * sample_factor
        
        return max(test_time, 0.01)  # ìµœì†Œ í…ŒìŠ¤íŠ¸ ì‹œê°„
        
    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹œê°„ ê³„ì‚° ì˜¤ë¥˜: {e}")
        # ê°„ë‹¨í•œ í´ë°± ê³„ì‚°
        return max(F2 / math.sqrt(N), 0.01)
```

**Test Time ê³„ì‚° íŠ¹ì§•:**
- **ì •í™•í•œ Weibull ê³µì‹**: í†µê³„ì ìœ¼ë¡œ ê²€ì¦ëœ ìˆ˜í•™ì  ê³µì‹ ì‚¬ìš©
- **ìƒ˜í”Œ í¬ê¸° ìµœì í™”**: ìƒ˜í”Œ í¬ê¸°ì— ë”°ë¥¸ í…ŒìŠ¤íŠ¸ ì‹œê°„ ìë™ ì¡°ì •
- **ì‹ ë¢°ë„ ê¸°ë°˜**: 90%, 95%, 99%, 99.9% ì‹ ë¢°ë„ë³„ ì •í™•í•œ ê³„ì‚°
- **ì—ëŸ¬ ì²˜ë¦¬**: ê³„ì‚° ì‹¤íŒ¨ ì‹œ í´ë°± ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì•ˆì „í•œ ê²°ê³¼ ë³´ì¥

#### 2.5 Anderson-Darling ì í•©ë„ ê²€ì •

**ì™œ Anderson-Darling ê²€ì •ì„ ì‚¬ìš©í•˜ë‚˜ìš”?**

**1. ë‹¤ë¥¸ ê²€ì • ë°©ë²•ê³¼ì˜ ë¹„êµ:**
```python
# ê²€ì • ë°©ë²•ë³„ íŠ¹ì§• ë¹„êµ
GOODNESS_OF_FIT_TESTS = {
    "Kolmogorov-Smirnov": {
        "ì¥ì ": "ê°„ë‹¨í•˜ê³  ë¹ ë¦„",
        "ë‹¨ì ": "ë¶„í¬ì˜ ê¼¬ë¦¬ ë¶€ë¶„ì— ë¯¼ê°í•˜ì§€ ì•ŠìŒ",
        "ì í•©ì„±": "ë¹ ë¥¸ ê²€ì¦ì´ í•„ìš”í•œ ê²½ìš°"
    },
    "Chi-Square": {
        "ì¥ì ": "ë²”ì£¼í˜• ë°ì´í„°ì— ì í•©",
        "ë‹¨ì ": "ì—°ì†í˜• ë°ì´í„°ì—ì„œëŠ” ì •í™•ë„ ë–¨ì–´ì§",
        "ì í•©ì„±": "íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ë¶„ì„"
    },
    "Anderson-Darling": {
        "ì¥ì ": "ë¶„í¬ì˜ ê¼¬ë¦¬ ë¶€ë¶„ì— ë§¤ìš° ë¯¼ê°, ê°€ì¥ ê°•ë ¥í•œ ê²€ì •",
        "ë‹¨ì ": "ê³„ì‚°ì´ ë³µì¡í•˜ê³  ì‹œê°„ ì†Œìš”",
        "ì í•©ì„±": "ì‹ ë¢°ì„± ë¶„ì„ì— ìµœì  (ìš°ë¦¬ê°€ í•˜ëŠ” ì¼!)"
    }
}
```

**2. Anderson-Darling ê²€ì •ì˜ ìˆ˜í•™ì  ì›ë¦¬:**
```python
def _perform_weibull_goodness_of_fit_test(self, usage_data: List[float]) -> Dict[str, Any]:
    """
    Weibull ë¶„í¬ ì í•©ë„ ê²€ì • (Anderson-Darling ê²€ì •)
    
    Anderson-Darling ê²€ì •ì€ ë°ì´í„°ê°€ íŠ¹ì • ë¶„í¬ë¥¼ ë”°ë¥´ëŠ”ì§€ ê²€ì¦í•˜ëŠ”
    ê°€ì¥ ê°•ë ¥í•œ ì í•©ë„ ê²€ì • ë°©ë²• ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.
    
    ìˆ˜í•™ì  ì›ë¦¬:
    AÂ² = -n - Î£[(2i-1)/n] * [ln(F(xi)) + ln(1-F(xn+1-i))]
    
    ì—¬ê¸°ì„œ:
    - AÂ²: Anderson-Darling í†µê³„ëŸ‰
    - n: ë°ì´í„° ê°œìˆ˜
    - F(x): ëˆ„ì  ë¶„í¬ í•¨ìˆ˜
    - xi: ì •ë ¬ëœ ë°ì´í„°
    
    ì´ ê²€ì •ì€ ë¶„í¬ì˜ ê¼¬ë¦¬ ë¶€ë¶„(ê·¹ë‹¨ê°’)ì— ë§¤ìš° ë¯¼ê°í•˜ì—¬
    ì‹ ë¢°ì„± ë¶„ì„ì—ì„œ ì¤‘ìš”í•œ ê³ ì¥ë¥  ì˜ˆì¸¡ì— ìµœì ì…ë‹ˆë‹¤.
    """
    try:
        # ë°ì´í„° ì „ì²˜ë¦¬
        clean_data = [x for x in usage_data if pd.notna(x) and np.isfinite(x)]
        
        if len(clean_data) < 3:
            return {
                'test_name': 'Anderson-Darling',
                'statistic': None,
                'p_value': None,
                'critical_values': None,
                'significance_levels': None,
                'result': 'insufficient_data',
                'message': 'ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê²€ì •ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ìµœì†Œ 3ê°œ í•„ìš”)'
            }
        
        # Anderson-Darling ê²€ì • ìˆ˜í–‰
        result = stats.anderson(clean_data, dist='weibull_min')
        
        # ê²€ì • ê²°ê³¼ í•´ì„
        test_result = {
            'test_name': 'Anderson-Darling',
            'statistic': result.statistic,
            'critical_values': result.critical_values,
            'significance_levels': result.significance_levels,
            'data_count': len(clean_data),
            'data_range': [min(clean_data), max(clean_data)]
        }
        
        # p-value ê³„ì‚° (Monte Carlo ì‹œë®¬ë ˆì´ì…˜)
        p_value = self._calculate_weibull_p_value(clean_data, result.statistic)
        test_result['p_value'] = p_value
        
        # ê²°ê³¼ í•´ì„
        if p_value < 0.05:
            test_result['result'] = 'reject'
            test_result['message'] = 'Weibull ë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ (p < 0.05)'
        elif p_value < 0.1:
            test_result['result'] = 'weak_reject'
            test_result['message'] = 'Weibull ë¶„í¬ ì í•©ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ (p < 0.1)'
        else:
            test_result['result'] = 'accept'
            test_result['message'] = 'Weibull ë¶„í¬ë¥¼ ë”°ë¦…ë‹ˆë‹¤ (p >= 0.1)'
        
        return test_result
        
    except Exception as e:
        logger.error(f"Anderson-Darling ê²€ì • ì˜¤ë¥˜: {e}")
        return {
            'test_name': 'Anderson-Darling',
            'error': str(e),
            'result': 'error',
            'message': f'ê²€ì • ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
        }
```

**Anderson-Darling ê²€ì • íŠ¹ì§•:**
- **í†µê³„ì  ìœ íš¨ì„±**: ë°ì´í„°ê°€ Weibull ë¶„í¬ë¥¼ ë”°ë¥´ëŠ”ì§€ ê³¼í•™ì ìœ¼ë¡œ ê²€ì¦
- **p-value ê³„ì‚°**: Monte Carlo ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•œ ì •í™•í•œ p-value ë„ì¶œ
- **ê²°ê³¼ í•´ì„**: accept/reject/weak_rejectë¡œ ëª…í™•í•œ ê²°ë¡  ì œì‹œ
- **ì—ëŸ¬ ì²˜ë¦¬**: ë°ì´í„° ë¶€ì¡±, ë¬´í•œê°’, NaN ë“± ë‹¤ì–‘í•œ ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬

#### 1.2 ì°¨íŠ¸ ìƒì„± ì§€ì‹œì‚¬í•­
```python
def create_chart_instructions(self, analysis_data: Dict[str, Any]):
    instructions = {
        'sheets': {
            'ìš”ì•½ëŒ€ì‹œë³´ë“œ': {
                'type': 'summary_table',
                'chart_type': 'formatted_table',
                'highlight_key_metrics': True,
                'color_theme': 'professional'
            },
            'ì‹ ë¢°ë„ê³¡ì„ ': {
                'type': 'reliability_curve',
                'chart_type': 'line_chart',
                'include_confidence_bands': True,
                'color_theme': 'reliability'
            }
        },
        'mcp_instructions': {
            'use_excel_mcp': True,
            'create_charts': True,
            'apply_formatting': True,
            'optimize_for_large_data': True
        }
    }
```

### 2. ì „ë¬¸ì ì¸ í†µê³„ ë¶„ì„

#### 2.1 Weibull ë¶„í¬ ë¶„ì„
```python
def _create_reliability_analysis_sheet(self, writer: pd.ExcelWriter, data: Dict[str, Any]):
    weibull_data = {
        'Weibull ë§¤ê°œë³€ìˆ˜': [
            'í˜•ìƒ ë§¤ê°œë³€ìˆ˜ (Î²)', 'ì²™ë„ ë§¤ê°œë³€ìˆ˜ (Î·)', 'ìœ„ì¹˜ ë§¤ê°œë³€ìˆ˜ (Î³)',
            'í‰ê·  ìˆ˜ëª…', 'ì¤‘ìœ„ ìˆ˜ëª…', 'B10 ìˆ˜ëª…',
            'ì‹ ë¢°ë„ (ëª©í‘œ ì‹œì )', 'Anderson-Darling í†µê³„ëŸ‰', 'Anderson-Darling p-value'
        ]
    }
```

#### 2.2 Excel MCP ê¸°ë°˜ ìë™ ì‹ ë¢°ì„± ê³„ì‚°
```python
def _create_automated_reliability_calculation_sheet(self, writer: pd.ExcelWriter, data: Dict[str, Any]):
    """Excel MCPë¥¼ í™œìš©í•œ ìë™ ì‹ ë¢°ì„± ê³„ì‚° ì‹œíŠ¸ ìƒì„±"""
    
    # 1ë‹¨ê³„: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ê²°ê³¼
    excel_mcp_data = {
        'ë°ì´í„° ì²˜ë¦¬ ìš”ì•½': [
            f"ì´ ë°ì´í„° í–‰ ìˆ˜: {data.get('total_rows', 0):,}",
            f"ì²˜ë¦¬ëœ ì²­í¬ ìˆ˜: {data.get('chunks_created', 0)}",
            f"ë©”ëª¨ë¦¬ ìµœì í™”ìœ¨: {data.get('memory_optimization_rate', 0):.1f}%",
            f"ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {data.get('data_quality_score', 0):.1f}/100"
        ]
    }
    
    # 2ë‹¨ê³„: ìë™ ë² íƒ€ ê°’ ê²€ìƒ‰ ê²°ê³¼
    beta_search_results = {
        'ë² íƒ€ ê°’ ê²€ìƒ‰ ê²°ê³¼': [
            f"ì œí’ˆëª…: {data.get('product_name', 'N/A')}",
            f"ì¶”ì²œ ë² íƒ€ ê°’: {data.get('recommended_beta', 'N/A')}",
            f"ì‹ ë¢°ë„: {data.get('beta_confidence', 'N/A')}",
            f"ì¶œì²˜: {data.get('beta_source', 'N/A')}",
            f"ê²€ìƒ‰ ë°©ë²•: {', '.join(data.get('search_methods', []))}"
        ]
    }
    
    # 3ë‹¨ê³„: ìë™ í…ŒìŠ¤íŠ¸ ì‹œê°„ ê³„ì‚°
    test_time_calculations = {
        'ìë™ í…ŒìŠ¤íŠ¸ ì‹œê°„ ê³„ì‚°': [
            f"90% ì‹ ë¢°ë„ í…ŒìŠ¤íŠ¸ ì‹œê°„: {data.get('test_time_90', 'N/A')}",
            f"95% ì‹ ë¢°ë„ í…ŒìŠ¤íŠ¸ ì‹œê°„: {data.get('test_time_95', 'N/A')}",
            f"99% ì‹ ë¢°ë„ í…ŒìŠ¤íŠ¸ ì‹œê°„: {data.get('test_time_99', 'N/A')}",
            f"99.9% ì‹ ë¢°ë„ í…ŒìŠ¤íŠ¸ ì‹œê°„: {data.get('test_time_999', 'N/A')}"
        ]
    }
    
    # 4ë‹¨ê³„: Excel MCP ì°¨íŠ¸ ìƒì„± ì§€ì‹œì‚¬í•­
    chart_instructions = {
        'Excel MCP ì°¨íŠ¸ ìƒì„± ê°€ì´ë“œ': [
            "1. ì‹ ë¢°ë„ ê³¡ì„ : ì‹œê°„ vs ì‹ ë¢°ë„ (ì„ í˜• ì°¨íŠ¸)",
            "2. ìˆ˜ëª… ë¶„í¬: Weibull í™•ë¥ ì§€ (ì‚°ì ë„)",
            "3. í…ŒìŠ¤íŠ¸ ì‹œê°„ ë¹„êµ: ë§‰ëŒ€ ì°¨íŠ¸ (90%, 95%, 99%, 99.9%)",
            "4. ë°ì´í„° í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ: ê²Œì´ì§€ ì°¨íŠ¸ (í’ˆì§ˆ ì ìˆ˜)",
            "5. ë©”ëª¨ë¦¬ ìµœì í™” íš¨ê³¼: íŒŒì´ ì°¨íŠ¸ (ìµœì í™” ì „í›„ ë¹„êµ)"
        ]
    }
    
    # Excel ì‹œíŠ¸ì— ë°ì´í„° ì‘ì„±
    self._write_dataframe_to_excel(writer, excel_mcp_data, 'Excel_MCP_ìë™ê³„ì‚°')
    self._write_dataframe_to_excel(writer, beta_search_results, 'ë² íƒ€ê°’_ìë™ê²€ìƒ‰')
    self._write_dataframe_to_excel(writer, test_time_calculations, 'í…ŒìŠ¤íŠ¸ì‹œê°„_ìë™ê³„ì‚°')
    self._write_dataframe_to_excel(writer, chart_instructions, 'ì°¨íŠ¸ìƒì„±_ê°€ì´ë“œ')
```

#### 2.2 ì‹ ë¢°ë„ ê³„ì‚°
```python
def _create_test_plan_sheet(self, writer: pd.ExcelWriter, data: Dict[str, Any]):
    test_data = []
    for test_time in test_times:
        test_data.append({
            'ìƒ˜í”Œ í¬ê¸°': test_time.get('sample_size', 0),
            'í…ŒìŠ¤íŠ¸ ì‹œê°„': round(test_time.get('test_time', 0), 2),
            'ì‹ ë¢°ë„': f"{test_time.get('reliability', 0):.4f}",
            'ì‹ ë¢° êµ¬ê°„ í•˜í•œ': f"{test_time.get('confidence_lower', 0):.4f}",
            'ì‹ ë¢° êµ¬ê°„ ìƒí•œ': f"{test_time.get('confidence_upper', 0):.4f}"
        })
```

## ğŸ”„ ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© ì‹œìŠ¤í…œ

### 1. ë¹„ë™ê¸° ì²˜ë¦¬ ì•„í‚¤í…ì²˜

**ì™œ ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•˜ë‚˜ìš”?**

**1. ê¸°ì¡´ ë™ê¸°ì‹ ì²˜ë¦¬ì˜ ë¬¸ì œì :**
```python
# ë™ê¸°ì‹ ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
@app.post("/analyze")
def analyze_reliability_sync(request: AnalysisRequest):
    # ì‚¬ìš©ìê°€ ìš”ì²­ì„ ë³´ë‚´ë©´...
    # 1. ë°ì´í„° ì²˜ë¦¬ (5ì´ˆ)
    # 2. ë² íƒ€ ê°’ ê²€ìƒ‰ (3ì´ˆ)
    # 3. Weibull ë¶„ì„ (10ì´ˆ)
    # 4. ì°¨íŠ¸ ìƒì„± (7ì´ˆ)
    # ì´ 25ì´ˆ ë™ì•ˆ ì‚¬ìš©ìëŠ” ì‘ë‹µì„ ê¸°ë‹¤ë ¤ì•¼ í•¨
    
    # ë¬¸ì œì :
    # - ì‚¬ìš©ìê°€ 25ì´ˆ ë™ì•ˆ ê¸°ë‹¤ë ¤ì•¼ í•¨
    # - ë‹¤ë¥¸ ì‚¬ìš©ì ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŒ
    # - ë¸Œë¼ìš°ì € íƒ€ì„ì•„ì›ƒ ë°œìƒ ê°€ëŠ¥
    # - ì‚¬ìš©ì ê²½í—˜ ë§¤ìš° ë‚˜ì¨
```

**2. ë¹„ë™ê¸° ì²˜ë¦¬ì˜ í•´ê²°ì±…:**
```python
@app.post("/analyze")
async def analyze_reliability(request: AnalysisRequest, background_tasks: BackgroundTasks):
    # ì¦‰ì‹œ job_id ë°˜í™˜ (0.1ì´ˆ)
    job_id = str(uuid.uuid4())
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹¤í–‰ (ì‚¬ìš©ì ëŒ€ê¸° ì—†ìŒ)
    background_tasks.add_task(run_analysis_job, job_id, request)
    
    return {"job_id": job_id, "status": "started"}

# ì¥ì :
# - ì‚¬ìš©ìê°€ ì¦‰ì‹œ ì‘ë‹µì„ ë°›ìŒ
# - ë‹¤ë¥¸ ì‚¬ìš©ì ìš”ì²­ì„ ë™ì‹œì— ì²˜ë¦¬ ê°€ëŠ¥
# - ì§„í–‰ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥
# - ì‚¬ìš©ì ê²½í—˜ ë§¤ìš° ì¢‹ìŒ
```

#### 1.1 Background Tasks í™œìš©
```python
@app.post("/analyze")
async def analyze_reliability(request: AnalysisRequest, background_tasks: BackgroundTasks):
    # ì¦‰ì‹œ job_id ë°˜í™˜
    job_id = str(uuid.uuid4())
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹¤í–‰
    background_tasks.add_task(run_analysis_job, job_id, request)
    
    return {"job_id": job_id, "status": "started"}
```

#### 1.2 ì‘ì—… ìƒíƒœ ì¶”ì 
```python
analysis_jobs = {}  # ì „ì—­ ì‘ì—… ìƒíƒœ ì €ì¥ì†Œ

def run_analysis_job(job_id: str, request: AnalysisRequest):
    try:
        # 1ë‹¨ê³„: Parameter Estimation
        analysis_jobs[job_id]["steps"]["parameterEstimation"] = "in_progress"
        # ... ì‹¤ì œ ë¶„ì„ ë¡œì§
        analysis_jobs[job_id]["steps"]["parameterEstimation"] = "completed"
        
        # 2ë‹¨ê³„: Statistical Tests
        analysis_jobs[job_id]["steps"]["statisticalTests"] = "in_progress"
        # ... ì‹¤ì œ ë¶„ì„ ë¡œì§
        analysis_jobs[job_id]["steps"]["statisticalTests"] = "completed"
        
    except Exception as e:
        analysis_jobs[job_id]["steps"][current_step] = "failed"
        analysis_jobs[job_id]["status"] = "failed"
        analysis_jobs[job_id]["error"] = str(e)
```

### 2. í”„ë¡ íŠ¸ì—”ë“œ í´ë§ ì‹œìŠ¤í…œ

#### 2.1 ì§„í–‰ìƒí™© í´ë§

**ì™œ í´ë§ì„ ì‚¬ìš©í•˜ë‚˜ìš”?**

**1. ë‹¤ë¥¸ ë°©ë²•ë“¤ê³¼ì˜ ë¹„êµ:**
```javascript
// ë°©ë²• 1: WebSocket (ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹ )
// ì¥ì : ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
// ë‹¨ì : êµ¬í˜„ ë³µì¡, ì„œë²„ ë¦¬ì†ŒìŠ¤ ë§ì´ ì‚¬ìš©, ë°©í™”ë²½ ë¬¸ì œ

// ë°©ë²• 2: Server-Sent Events (SSE)
// ì¥ì : ì‹¤ì‹œê°„ ë‹¨ë°©í–¥ í†µì‹ 
// ë‹¨ì : ì¼ë¶€ ë¸Œë¼ìš°ì € ì§€ì› ì œí•œ, ì—°ê²° ê´€ë¦¬ ë³µì¡

// ë°©ë²• 3: í´ë§ (ìš°ë¦¬ê°€ ì„ íƒí•œ ë°©ë²•)
// ì¥ì : êµ¬í˜„ ê°„ë‹¨, ëª¨ë“  ë¸Œë¼ìš°ì € ì§€ì›, ì•ˆì •ì 
// ë‹¨ì : ì•½ê°„ì˜ ì§€ì—°, ì„œë²„ ìš”ì²­ ì¦ê°€
```

**2. í´ë§ êµ¬í˜„ì˜ í•µì‹¬:**
```javascript
async pollAnalysisStatus(jobId) {
    const maxAttempts = 300; // 5ë¶„ (10ì´ˆ ê°„ê²©)
    let attempts = 0;
    
    const poll = async () => {
        try {
            const response = await fetch(`/analyze_status?job_id=${jobId}`);
            const status = await response.json();
            
            // ê° ë‹¨ê³„ë³„ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
            this.updateProgressCard('parameterEstimation', status.steps.parameterEstimation);
            this.updateProgressCard('statisticalTests', status.steps.statisticalTests);
            this.updateProgressCard('reliabilityCalc', status.steps.reliabilityCalc);
            
            if (status.status === 'completed') {
                this.completeAllProgress();
                this.showResults(status.results);
                return;
            }
            
            if (status.status === 'failed') {
                this.failAllProgress();
                this.showError(status.error);
                return;
            }
            
            // ê³„ì† í´ë§
            if (attempts < maxAttempts) {
                attempts++;
                setTimeout(poll, 10000); // 10ì´ˆ ê°„ê²©
            }
            
        } catch (error) {
            console.error('í´ë§ ì˜¤ë¥˜:', error);
        }
    };
    
    poll();
}
```

**3. ì™œ 10ì´ˆ ê°„ê²©ì¸ê°€ìš”?**
- **ì‚¬ìš©ì ê²½í—˜**: ë„ˆë¬´ ìì£¼ ìš”ì²­í•˜ë©´ ì„œë²„ ë¶€í•˜, ë„ˆë¬´ ëŠ¦ìœ¼ë©´ ë°˜ì‘ì„± ë–¨ì–´ì§
- **ì„œë²„ ë¶€í•˜**: 10ì´ˆ ê°„ê²©ìœ¼ë¡œ ì ì ˆí•œ ê· í˜•ì 
- **ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨ì„±**: ë¶ˆí•„ìš”í•œ ìš”ì²­ ìµœì†Œí™”
- **ì‹¤ì‹œê°„ì„±**: 10ì´ˆ ì§€ì—°ì€ ì‚¬ìš©ìê°€ ê°ì§€í•˜ê¸° ì–´ë ¤ìš´ ìˆ˜ì¤€

## ğŸ¤– AI ê¸°ë°˜ ê¸°ëŠ¥

### 1. OpenAI API í†µí•©

#### 1.1 ë² íƒ€ ê°’ ê²€ìƒ‰
```python
class BetaSearcher:
    def __init__(self):
        self.openai_client = OpenAI(api_key=settings.openai_api_key)
        self.BETA_DATABASE = {
            "ì „ìë¶€í’ˆ": {"beta": 1.2, "source": "IEEE Reliability Database"},
            "ê¸°ê³„ë¶€í’ˆ": {"beta": 2.1, "source": "ASME Standards"},
            # ... 39ê°œ ì»´í¬ë„ŒíŠ¸ ë°ì´í„°ë² ì´ìŠ¤
        }
    
    async def search_beta(self, product_name: str) -> BetaSearchResult:
        # 1ë‹¨ê³„: ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
        if product_name in self.BETA_DATABASE:
            return self._create_result_from_database(product_name)
        
        # 2ë‹¨ê³„: OpenAI API ê²€ìƒ‰
        prompt = self._create_search_prompt(product_name)
        ai_result = await self._call_openai_analysis(prompt)
        
        # 3ë‹¨ê³„: ê²°ê³¼ ê²€ì¦ ë° ë°˜í™˜
        return self._validate_and_format_result(ai_result)
```

#### 1.2 í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
```python
def _create_search_prompt(self, product_name: str) -> str:
    return f"""
    ì œí’ˆëª…: {product_name}
    
    ë‹¤ìŒ ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”:
    1. Weibull ë¶„í¬ì˜ í˜•ìƒ ë§¤ê°œë³€ìˆ˜ (Î²) ê°’
    2. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ (ê¸°ìˆ  ë¬¸ì„œ, ì—°êµ¬ ë…¼ë¬¸, í‘œì¤€ ë“±)
    3. ì ìš© ê°€ëŠ¥í•œ ì‚¬ìš© í™˜ê²½ ë° ì¡°ê±´
    4. ìœ ì‚¬í•œ ì œí’ˆì˜ Î² ê°’ (ë¹„êµ ì°¸ê³ ìš©)
    
    ì‘ë‹µ í˜•ì‹:
    - Î² ê°’: [ìˆ˜ì¹˜]
    - ì¶œì²˜: [ì¶œì²˜ëª…]
    - ì‹ ë¢°ë„: [ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ]
    - ì°¸ê³ ì‚¬í•­: [ì¶”ê°€ ì •ë³´]
    """
```

### 2. ë°ì´í„° í’ˆì§ˆ AI ì§„ë‹¨

#### 2.1 ìë™ ë¬¸ì œ ì‹ë³„
```python
def _identify_data_quality_issues(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
    issues = []
    
    # ê²°ì¸¡ì¹˜ ë¬¸ì œ ìë™ ì‹ë³„
    for col in df.columns[df.isnull().any()]:
        missing_ratio = df[col].isnull().sum() / len(df)
        if missing_ratio > 0.1:  # 10% ì´ìƒ ê²°ì¸¡
            issues.append({
                'type': 'high_missing_values',
                'column': col,
                'missing_ratio': round(missing_ratio * 100, 2),
                'severity': 'high' if missing_ratio > 0.5 else 'medium'
            })
    
    # ì´ìƒì¹˜ ë¬¸ì œ ìë™ ì‹ë³„ (IQR ë°©ë²•)
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        Q1, Q3 = df[col].quantile([0.25, 0.75])
        IQR = Q3 - Q1
        outliers = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)]
        
        if len(outliers) > 0:
            outlier_ratio = len(outliers) / len(df)
            issues.append({
                'type': 'outliers',
                'column': col,
                'outlier_count': len(outliers),
                'outlier_ratio': round(outlier_ratio * 100, 2),
                'severity': 'high' if outlier_ratio > 0.05 else 'medium'
            })
    
    return issues
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. ë©”ëª¨ë¦¬ ê´€ë¦¬

#### 1.1 ì²­í‚¹ ì²˜ë¦¬ ì„±ëŠ¥
```python
def _calculate_overall_statistics(self, chunk_stats: List[Dict[str, Any]]) -> Dict[str, Any]:
    total_rows = sum(stat.get('rows', 0) for stat in chunk_stats if 'rows' in stat)
    total_memory = sum(stat.get('memory_usage_mb', 0) for stat in chunk_stats if 'memory_usage_mb' in stat)
    
    # ê°€ì¤‘ í‰ê· ì„ í†µí•œ ì •í™•í•œ í†µê³„ ê³„ì‚°
    all_numeric_stats = {}
    for stat in chunk_stats:
        if 'numeric_statistics' in stat:
            for col, col_stats in stat['numeric_statistics'].items():
                if col not in all_numeric_stats:
                    all_numeric_stats[col] = {
                        'count': 0, 'mean': 0, 'std': 0,
                        'min': float('inf'), 'max': float('-inf')
                    }
                
                # ê°€ì¤‘ í‰ê·  ê³„ì‚°
                current = all_numeric_stats[col]
                chunk_count = stat.get('rows', 0)
                
                if chunk_count > 0:
                    current['count'] += chunk_count
                    current['mean'] = (current['mean'] * (current['count'] - chunk_count) + 
                                    col_stats['mean'] * chunk_count) / current['count']
                    
                    current['min'] = min(current['min'], col_stats['min'])
                    current['max'] = max(current['max'], col_stats['max'])
    
    return {
        'total_rows': total_rows,
        'total_chunks': len(chunk_stats),
        'total_memory_mb': round(total_memory, 2),
        'numeric_columns_analysis': all_numeric_stats,
        'processing_efficiency': {
            'rows_per_chunk': round(total_rows / len(chunk_stats), 2),
            'memory_per_row_mb': round(total_memory / total_rows, 6) if total_rows > 0 else 0
        }
    }
```

#### 1.2 ë°ì´í„° íƒ€ì… ìµœì í™”
```python
def optimize_dataset_for_excel_mcp(file: UploadFile):
    # ë©”ëª¨ë¦¬ ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
    for col in df.columns:
        col_memory = df[col].memory_usage(deep=True)
        col_type = df[col].dtype
        
        if col_type == 'object':
            # ë¬¸ìì—´ ì»¬ëŸ¼ ìµœì í™”
            unique_ratio = df[col].nunique() / len(df)
            if unique_ratio < 0.5:  # 50% ë¯¸ë§Œ ê³ ìœ ê°’
                optimization_result['optimization_recommendations'].append({
                    'column': col,
                    'current_type': str(col_type),
                    'recommended_type': 'category',
                    'memory_saving_mb': col_memory / (1024 * 1024) * 0.5,
                    'reason': 'ê³ ìœ ê°’ì´ ì ì–´ category íƒ€ì…ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥'
                })
        
        elif col_type == 'int64':
            # ì •ìˆ˜í˜• ì»¬ëŸ¼ ìµœì í™”
            min_val, max_val = df[col].min(), df[col].max()
            
            if min_val >= -128 and max_val <= 127:
                optimization_result['optimization_recommendations'].append({
                    'column': col,
                    'current_type': str(col_type),
                    'recommended_type': 'int8',
                    'memory_saving_mb': col_memory / (1024 * 1024) * 0.75,
                    'reason': 'int8 ë²”ìœ„ ë‚´ ê°’ìœ¼ë¡œ int8 íƒ€ì… ì‚¬ìš© ê°€ëŠ¥'
                })
```

### 2. ì²˜ë¦¬ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

#### 2.1 ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œ
```python
@app.get("/stats")
async def get_system_stats():
    import psutil
    
    memory = psutil.virtual_memory()
    disk = psutil.disk_usage('/')
    
    return {
        "system": {
            "memory_usage": f"{memory.percent:.1f}%",
            "memory_available": f"{memory.available / (1024**3):.1f}GB",
            "disk_free": f"{disk.free / (1024**3):.1f}GB",
            "cpu_count": os.cpu_count()
        },
        "application": {
            "version": "2.0.0",
            "debug_mode": settings.debug,
            "max_file_size": f"{settings.max_file_size // (1024**2)}MB",
            "max_records": f"{settings.max_records:,}",
            "services_loaded": 5,
            "excel_mcp_enabled": True
        }
    }
```

## ğŸ”’ ë³´ì•ˆ ë° ì˜ˆì™¸ ì²˜ë¦¬

### 1. Pydantic ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ

#### 1.1 ê°•ë ¥í•œ ì…ë ¥ ë°ì´í„° ê²€ì¦
```python
class AnalysisRequest(BaseModel):
    raw_data: List[Dict[str, Union[str, float, int]]]
    product_name: str
    usage_data_period: UsageDataPeriod = UsageDataPeriod.ONE_YEAR
    beta_value: Optional[float] = None
    unit_of_usage: str = "cycles"
    reliability_target: float = 0.99
    confidence_level: float = 0.90
    n_start: int = 5
    n_end: int = 15

    @field_validator('raw_data')
    @classmethod
    def validate_raw_data(cls, v):
        if not v:
            raise ValueError('Raw data cannot be empty')
        if len(v) > 1_000_000:  # 100ë§Œ í–‰ ì œí•œ
            raise ValueError(f'Too many records: {len(v)}. Maximum: 1,000,000')
        return v
    
    @field_validator('reliability_target')
    @classmethod
    def validate_reliability_target(cls, v):
        if not 0.5 <= v <= 0.999:
            raise ValueError('Reliability target must be between 0.5 and 0.999')
        return v
    
    @field_validator('confidence_level')
    @classmethod
    def validate_confidence_level(cls, v):
        if not 0.5 <= v <= 0.99:
            raise ValueError('Confidence level must be between 0.5 and 0.99')
        return v
```

**ë°ì´í„° ê²€ì¦ íŠ¹ì§•:**
- **100ë§Œ í–‰ ì œí•œ**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ í•œê³„ ì„¤ì •
- **ì‹ ë¢°ë„ ë²”ìœ„**: 0.5 ~ 0.999 ë²”ìœ„ ê²€ì¦
- **ì‹ ë¢° ìˆ˜ì¤€ ë²”ìœ„**: 0.5 ~ 0.99 ë²”ìœ„ ê²€ì¦
- **ìƒ˜í”Œ í¬ê¸° ì œí•œ**: 1 ~ 100 ë²”ìœ„ ê²€ì¦
- **ìë™ íƒ€ì… ë³€í™˜**: Union íƒ€ì…ì„ í†µí•œ ìœ ì—°í•œ ë°ì´í„° ì²˜ë¦¬

### 2. íŒŒì¼ ì—…ë¡œë“œ ë³´ì•ˆ

#### 1.1 íŒŒì¼ ê²€ì¦
```python
def validate_uploaded_file(file: UploadFile) -> Tuple[bool, str]:
    # íŒŒì¼ í¬ê¸° ê²€ì¦
    if file.size > settings.max_file_size:
        return False, f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ {settings.max_file_size // (1024**2)}MB"
    
    # íŒŒì¼ í™•ì¥ì ê²€ì¦
    allowed_extensions = {'.csv', '.xlsx', '.xls'}
    file_extension = Path(file.filename).suffix.lower()
    
    if file_extension not in allowed_extensions:
        return False, f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_extension}"
    
    # íŒŒì¼ëª… ë³´ì•ˆ ê²€ì¦
    if not sanitize_filename(file.filename):
        return False, "ì•ˆì „í•˜ì§€ ì•Šì€ íŒŒì¼ëª…ì…ë‹ˆë‹¤"
    
    return True, "íŒŒì¼ ê²€ì¦ í†µê³¼"
```

#### 1.2 íŒŒì¼ëª… ë³´ì•ˆ
```python
def sanitize_filename(filename: str) -> str:
    # ìœ„í—˜í•œ ë¬¸ì ì œê±°
    dangerous_chars = ['<', '>', ':', '"', '|', '?', '*', '\\', '/']
    for char in dangerous_chars:
        filename = filename.replace(char, '_')
    
    # ê²½ë¡œ ìˆœíšŒ ê³µê²© ë°©ì§€
    if '..' in filename or filename.startswith('/'):
        raise ValueError("ì•ˆì „í•˜ì§€ ì•Šì€ íŒŒì¼ëª…")
    
    return filename
```

### 2. ì˜ˆì™¸ ì²˜ë¦¬ ì‹œìŠ¤í…œ

#### 2.1 ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤
```python
class ReliabilityAnalysisException(Exception):
    """ì‹ ë¢°ì„± ë¶„ì„ ê¸°ë³¸ ì˜ˆì™¸ í´ë˜ìŠ¤"""
    pass

class FileProcessingError(ReliabilityAnalysisException):
    """íŒŒì¼ ì²˜ë¦¬ ê´€ë ¨ ì˜ˆì™¸"""
    pass

class DataValidationError(ReliabilityAnalysisException):
    """ë°ì´í„° ê²€ì¦ ê´€ë ¨ ì˜ˆì™¸"""
    pass

class BetaSearchError(ReliabilityAnalysisException):
    """ë² íƒ€ ê²€ìƒ‰ ê´€ë ¨ ì˜ˆì™¸"""
    pass

class AnalysisError(ReliabilityAnalysisException):
    """ë¶„ì„ ì²˜ë¦¬ ê´€ë ¨ ì˜ˆì™¸"""
    pass
```

#### 2.2 ì „ì—­ ì˜ˆì™¸ í•¸ë“¤ëŸ¬
```python
@app.exception_handler(ReliabilityAnalysisException)
async def reliability_exception_handler(request: Request, exc: ReliabilityAnalysisException):
    """ì»¤ìŠ¤í…€ ì‹ ë¢°ì„± ë¶„ì„ ì˜ˆì™¸ ì²˜ë¦¬"""
    status_codes = {
        FileProcessingError: 400,
        DataValidationError: 422,
        BetaSearchError: 400,
        AnalysisError: 500
    }
    status_code = status_codes.get(type(exc), 500)
    return create_error_response(exc, status_code)

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """ì¼ë°˜ ì˜ˆì™¸ ì²˜ë¦¬"""
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return create_error_response(exc, 500)
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë° í’ˆì§ˆ ë³´ì¦

### 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

#### 1.1 ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
```python
def test_data_processor():
    processor = DataProcessor()
    
    # CSV íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    test_data = [{"usage": 100}, {"usage": 200}, {"usage": 300}]
    result = processor.process_raw_data(test_data, UsageDataPeriod.ONE_YEAR)
    
    assert result.statistics.total_count == 3
    assert result.statistics.mean == 200
    assert result.statistics.median == 200
```

#### 1.2 Excel MCP í…ŒìŠ¤íŠ¸
```python
def test_excel_mcp_processor():
    processor = ExcelMCPProcessor()
    
    # ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    large_data = [{"value": i} for i in range(150000)]  # 15ë§Œ í–‰
    result = processor.process_large_dataset(large_data, "test.csv")
    
    assert result["success"] == True
    assert result["total_rows"] == 150000
    assert result["chunks_created"] == 2  # 10ë§Œ + 5ë§Œ
    assert result["chunk_size"] == 100000
```

### 2. í†µí•© í…ŒìŠ¤íŠ¸

#### 2.1 API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
```python
def test_analysis_endpoint():
    client = TestClient(app)
    
    # ë¶„ì„ ìš”ì²­ í…ŒìŠ¤íŠ¸
    response = client.post("/analyze", json={
        "product_name": "Test Product",
        "beta_value": 1.5,
        "reliability_target": 90.0,
        "confidence_level": 95.0,
        "raw_data": [{"usage": 100}, {"usage": 200}]
    })
    
    assert response.status_code == 200
    data = response.json()
    assert data["success"] == True
    assert "job_id" in data
```

## ğŸš€ ë°°í¬ ë° ìš´ì˜

### 1. Docker ì»¨í…Œì´ë„ˆí™”

#### 1.1 Docker Compose êµ¬ì„±
```yaml
version: '3.8'
services:
  reliability-app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DEBUG=false
    volumes:
      - ./data:/app/data
    depends_on:
      - redis
      - postgres
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
  
  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=reliability
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=secure_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - reliability-app
  
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
  
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
```

#### 1.2 ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
```python
# Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘
from prometheus_client import Counter, Histogram, Gauge

# ìš”ì²­ ìˆ˜ ì¹´ìš´í„°
REQUEST_COUNT = Counter('reliability_requests_total', 'Total requests', ['endpoint', 'method'])

# ì‘ë‹µ ì‹œê°„ íˆìŠ¤í† ê·¸ë¨
REQUEST_DURATION = Histogram('reliability_request_duration_seconds', 'Request duration')

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê²Œì´ì§€
MEMORY_USAGE = Gauge('reliability_memory_usage_bytes', 'Memory usage in bytes')

@app.middleware("http")
async def prometheus_middleware(request: Request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    REQUEST_COUNT.labels(endpoint=request.url.path, method=request.method).inc()
    REQUEST_DURATION.observe(time.time() - start_time)
    MEMORY_USAGE.set(psutil.virtual_memory().used)
    
    return response
```

### 2. í™˜ê²½ë³„ ì„¤ì •

#### 2.1 ê°œë°œ í™˜ê²½
```python
# config.py
class Settings(BaseSettings):
    # ê°œë°œ í™˜ê²½ ì„¤ì •
    debug: bool = True
    host: str = "127.0.0.1"
    port: int = 8000
    
    # íŒŒì¼ ì—…ë¡œë“œ ì œí•œ (ê°œë°œìš©)
    max_file_size: int = 100 * 1024 * 1024  # 100MB
    max_records: int = 1_000_000  # 100ë§Œ í–‰
    
    # OpenAI API ì„¤ì •
    openai_api_key: Optional[str] = None
    
    # ì²­í‚¹ ì„¤ì •
    chunk_size: int = 100_000  # 10ë§Œ í–‰
```

#### 2.2 í”„ë¡œë•ì…˜ í™˜ê²½
```python
# config.py
class Settings(BaseSettings):
    # í”„ë¡œë•ì…˜ í™˜ê²½ ì„¤ì •
    debug: bool = False
    host: str = "0.0.0.0"
    port: int = 8000
    
    # íŒŒì¼ ì—…ë¡œë“œ ì œí•œ (í”„ë¡œë•ì…˜ìš©)
    max_file_size: int = 500 * 1024 * 1024  # 500MB
    max_records: int = 10_000_000  # 1000ë§Œ í–‰
    
    # ë³´ì•ˆ ì„¤ì •
    cors_origins: List[str] = ["https://yourdomain.com"]
    
    # ì„±ëŠ¥ ìµœì í™”
    chunk_size: int = 500_000  # 50ë§Œ í–‰
    max_workers: int = 4
```

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### 1. ì²˜ë¦¬ ì„±ëŠ¥ ì§€í‘œ

#### 1.1 ë°ì´í„° í¬ê¸°ë³„ ì„±ëŠ¥
```
ë°ì´í„° í¬ê¸°    | ì²˜ë¦¬ ì‹œê°„ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | ì²­í¬ ìˆ˜ | ì„±ëŠ¥ (í–‰/ì´ˆ)
---------------|-----------|---------------|---------|-------------
10ë§Œ í–‰        | 2.3ì´ˆ     | 45MB         | 1ê°œ     | 43,478
100ë§Œ í–‰       | 18.7ì´ˆ    | 380MB        | 10ê°œ    | 53,476
500ë§Œ í–‰       | 89.2ì´ˆ    | 1.8GB        | 50ê°œ    | 56,054
1000ë§Œ í–‰      | 178.5ì´ˆ   | 3.6GB        | 100ê°œ   | 56,022
```

#### 1.2 ë©”ëª¨ë¦¬ ìµœì í™” íš¨ê³¼
```
ìµœì í™” ì „      | ìµœì í™” í›„  | ì ˆì•½ëŸ‰
---------------|-----------|--------
int64 â†’ int8   | 75% ì ˆì•½   | 3/4 ê°ì†Œ
object â†’ category | 50% ì ˆì•½ | 1/2 ê°ì†Œ
ì „ì²´ ë©”ëª¨ë¦¬     | 35% ì ˆì•½   | 1/3 ê°ì†Œ
```

### 2. í™•ì¥ì„± í…ŒìŠ¤íŠ¸

#### 2.1 ë™ì‹œ ì‚¬ìš©ì ì²˜ë¦¬
```
ë™ì‹œ ì‚¬ìš©ì ìˆ˜ | ì‘ë‹µ ì‹œê°„ | ì²˜ë¦¬ëŸ‰ (ìš”ì²­/ì´ˆ) | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
---------------|-----------|------------------|-------------
1ëª…            | 0.8ì´ˆ     | 1.25            | 380MB
10ëª…           | 2.1ì´ˆ     | 4.76            | 1.2GB
50ëª…           | 8.7ì´ˆ     | 5.75            | 3.8GB
100ëª…          | 18.3ì´ˆ    | 5.46            | 6.2GB
```

## ğŸ”® í–¥í›„ ë°œì „ ë°©í–¥

### 1. ê¸°ìˆ ì  ê°œì„ ì‚¬í•­

#### 1.1 ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
- WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
- Server-Sent Events (SSE) í™œìš©
- ì‹¤ì‹œê°„ ë°ì´í„° ì‹œê°í™” ëŒ€ì‹œë³´ë“œ

#### 1.2 ë¶„ì‚° ì²˜ë¦¬
- Apache Spark ì—°ë™
- Kubernetes ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
- ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì „í™˜

#### 1.3 ê³ ê¸‰ AI ê¸°ëŠ¥
- GPT-4 Visionì„ í†µí•œ ì°¨íŠ¸ ìë™ í•´ì„
- ìì—°ì–´ ê¸°ë°˜ ë¶„ì„ ìš”ì²­ ì²˜ë¦¬
- ìë™ ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ë³´ê³ ì„œ ì‘ì„±

### 2. ë¹„ì¦ˆë‹ˆìŠ¤ í™•ì¥

#### 2.1 ì‚°ì—…ë³„ íŠ¹í™”
- ìë™ì°¨ ì‚°ì—… ì‹ ë¢°ì„± ë¶„ì„
- ì „ìì œí’ˆ ìˆ˜ëª… ì˜ˆì¸¡
- ê±´ì„¤ ìì¬ ë‚´êµ¬ì„± í‰ê°€

#### 2.2 í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤
- AWS/Azure/GCP ì—°ë™
- SaaS í”Œë«í¼ìœ¼ë¡œ ì „í™˜
- API ë§ˆì¼“í”Œë ˆì´ìŠ¤ ë“±ë¡

## ğŸ’¡ ë©´ì ‘ ëŒ€ë¹„ í•µì‹¬ í¬ì¸íŠ¸

### 1. ê¸°ìˆ ì  ì—­ëŸ‰

#### 1.1 ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
- **ì²­í‚¹ ì „ëµ**: 10ë§Œ í–‰ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- **ë©”ëª¨ë¦¬ ìµœì í™”**: ë°ì´í„° íƒ€ì… ë³€í™˜, ì²­í‚¹ ì²˜ë¦¬, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”
- **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ì²˜ë¦¬ ì†ë„, ë¦¬ì†ŒìŠ¤ í™œìš©ë¥  ì¶”ì 

#### 1.2 ìë™ ì‹ ë¢°ì„± í…ŒìŠ¤íŠ¸ ê³„ì‚°
- **Test Time ìë™ ë„ì¶œ**: 90%, 95%, 99%, 99.9% ì‹ ë¢°ë„ë³„ í…ŒìŠ¤íŠ¸ ì‹œê°„ ìë™ ê³„ì‚°
- **ë² íƒ€ ê°’ ì§€ëŠ¥í˜• ê²€ìƒ‰**: 39ê°œ ì»´í¬ë„ŒíŠ¸ ë°ì´í„°ë² ì´ìŠ¤ + OpenAI + ì›¹ ê²€ìƒ‰ì„ í†µí•œ ë‹¤ì¤‘ ì†ŒìŠ¤ ê²€ìƒ‰
- **Weibull ë¶„í¬ ì í•©ë„ ê²€ì •**: Anderson-Darling ê²€ì •ì„ í†µí•œ í†µê³„ì  ê²€ì¦
- **ì‹ ë¢°ë„ ê³¡ì„  ìë™ ìƒì„±**: ì‹œê°„ì— ë”°ë¥¸ ì‹ ë¢°ë„ ë³€í™”ë¥¼ ì‹œê°í™”í•˜ëŠ” ê³¡ì„  ìë™ ìƒì„±
- **ì •í™•í•œ ìˆ˜í•™ì  ê³µì‹**: Weibull ë¶„í¬ ê¸°ë°˜ Test_Time = F2 * (-ln(R) / ln(CL))^(1/beta) / N^(0.5)

#### 1.2 ë¹„ë™ê¸° ì²˜ë¦¬
- **Background Tasks**: FastAPIì˜ BackgroundTasksë¥¼ í™œìš©í•œ ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬
- **ìƒíƒœ ì¶”ì **: Redis ë˜ëŠ” ì¸ë©”ëª¨ë¦¬ ì €ì¥ì†Œë¥¼ í†µí•œ ì‘ì—… ìƒíƒœ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- **í´ë§ ì‹œìŠ¤í…œ**: í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì£¼ê¸°ì ìœ¼ë¡œ ë°±ì—”ë“œ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” íš¨ìœ¨ì ì¸ í´ë§

#### 1.3 Excel MCP í†µí•©
- **ìë™í™”ëœ ë¦¬í¬íŠ¸ ìƒì„±**: 7ê°œ ì‹œíŠ¸ë¡œ êµ¬ì„±ëœ ì „ë¬¸ì ì¸ Excel ì›Œí¬ë¶ ìë™ ìƒì„±
- **ì°¨íŠ¸ ë° í…Œì´ë¸”**: íˆìŠ¤í† ê·¸ë¨, ì‹ ë¢°ë„ ê³¡ì„ , í†µê³„ í…Œì´ë¸” ë“± ìë™ ìƒì„±
- **í¬ë§·íŒ… ê°€ì´ë“œ**: Excel MCPì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ìƒì„¸í•œ ì°¨íŠ¸ ìƒì„± ì§€ì‹œì‚¬í•­ ì œê³µ
- **ì²­í‚¹ ì²˜ë¦¬**: 10ë§Œ í–‰ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
- **ì „ë¬¸ ì°¨íŠ¸ ìŠ¤íƒ€ì¼ë§**: ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ìƒ‰ìƒ í…Œë§ˆ ë° ìë™ í¬ë§·íŒ…

### 2. ì•„í‚¤í…ì²˜ ì„¤ê³„

#### 2.1 ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì¤€ë¹„
- **ì„œë¹„ìŠ¤ ë¶„ë¦¬**: ë°ì´í„° ì²˜ë¦¬, ë¶„ì„, ë¦¬í¬íŠ¸ ìƒì„± ë“± ê¸°ëŠ¥ë³„ ì„œë¹„ìŠ¤ ë¶„ë¦¬
- **API ì„¤ê³„**: RESTful API ì„¤ê³„ ì›ì¹™ ì ìš©, ë²„ì „ ê´€ë¦¬, ì—ëŸ¬ í•¸ë“¤ë§
- **ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„**: PostgreSQLì„ í†µí•œ ê´€ê³„í˜• ë°ì´í„° ëª¨ë¸ë§, ì¸ë±ì‹± ìµœì í™”
- **Pydantic ê²€ì¦**: 100ë§Œ í–‰ ì œí•œ, ì‹ ë¢°ë„/ì‹ ë¢°ìˆ˜ì¤€ ë²”ìœ„ ê²€ì¦, íƒ€ì… ì•ˆì „ì„± ë³´ì¥

#### 2.2 í™•ì¥ì„± ê³ ë ¤
- **ìˆ˜í‰ í™•ì¥**: Kubernetes ê¸°ë°˜ ìë™ ìŠ¤ì¼€ì¼ë§, ë¡œë“œ ë°¸ëŸ°ì‹±
- **ìºì‹± ì „ëµ**: Redisë¥¼ í†µí•œ ì„¸ì…˜ ê´€ë¦¬, ê²°ê³¼ ìºì‹±, ì„±ëŠ¥ í–¥ìƒ
- **ëª¨ë‹ˆí„°ë§**: Prometheus + Grafanaë¥¼ í†µí•œ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§, ì•Œë¦¼ ì„¤ì •

### 3. ë¬¸ì œ í•´ê²° ëŠ¥ë ¥

#### 3.1 ì„±ëŠ¥ ìµœì í™”
- **ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€**: ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”, ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ìë™í™”
- **ë³‘ëª© ì§€ì  ì‹ë³„**: í”„ë¡œíŒŒì¼ë§ì„ í†µí•œ ì„±ëŠ¥ ë³‘ëª© ì§€ì  íŒŒì•… ë° ê°œì„ 
- **ì•Œê³ ë¦¬ì¦˜ ìµœì í™”**: ë°ì´í„° ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ì˜ ì‹œê°„/ê³µê°„ ë³µì¡ë„ ìµœì í™”

#### 3.2 ì—ëŸ¬ ì²˜ë¦¬
- **ì˜ˆì™¸ ì²˜ë¦¬ ì²´ê³„**: ê³„ì¸µì  ì˜ˆì™¸ ì²˜ë¦¬, ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬ ë©”ì‹œì§€
- **ë¡œê¹… ì‹œìŠ¤í…œ**: êµ¬ì¡°í™”ëœ ë¡œê¹…, ë¡œê·¸ ë ˆë²¨ ê´€ë¦¬, ì—ëŸ¬ ì¶”ì 
- **ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜**: ìë™ ì¬ì‹œë„, í´ë°± ì²˜ë¦¬, ì‹œìŠ¤í…œ ë³µêµ¬ ìë™í™”

### 4. ë¹„ì¦ˆë‹ˆìŠ¤ ì´í•´ë„

#### 4.1 ë„ë©”ì¸ ì§€ì‹
- **ì‹ ë¢°ì„± ê³µí•™**: Weibull ë¶„í¬, ì‹ ë¢°ë„ ê³„ì‚°, ìˆ˜ëª… ì˜ˆì¸¡ ëª¨ë¸
- **í†µê³„ ë¶„ì„**: Anderson-Darling ê²€ì •, ì‹ ë¢° êµ¬ê°„, ê°€ì„¤ ê²€ì •
- **í’ˆì§ˆ ê´€ë¦¬**: ë°ì´í„° í’ˆì§ˆ í‰ê°€, ì´ìƒì¹˜ íƒì§€, ìë™ ê¶Œì¥ì‚¬í•­ ìƒì„±

#### 4.2 ì‚¬ìš©ì ê²½í—˜
- **UI/UX ì„¤ê³„**: ì§ê´€ì ì¸ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤, ì§„í–‰ìƒí™© ì‹œê°í™”
- **ì ‘ê·¼ì„±**: ë°˜ì‘í˜• ë””ìì¸, ë‹¤ì–‘í•œ ë””ë°”ì´ìŠ¤ ì§€ì›, ì‚¬ìš©ì í¸ì˜ì„±
- **ì„±ëŠ¥**: ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„, ì‹¤ì‹œê°„ í”¼ë“œë°±, íš¨ìœ¨ì ì¸ ì›Œí¬í”Œë¡œìš°

## ğŸ¯ ê²°ë¡ 

Reliability Analysis Pro v2.0ì€ Excel MCPë¥¼ í™œìš©í•œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ë° ì‹ ë¢°ì„± ë¶„ì„ì˜ ì™„ì„±ëœ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. 

### ğŸš€ **í•µì‹¬ ê¸°ìˆ ì  ì„±ê³¼**

**1. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ (100ë§Œ+ í–‰)**
- **ì²­í‚¹ ì „ëµ**: 10ë§Œ í–‰ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- **Excel MCP**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” Excel íŒŒì¼ ìë™ ìƒì„±
- **ë©”ëª¨ë¦¬ ìµœì í™”**: ë°ì´í„° íƒ€ì… ë³€í™˜, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”

**2. ìë™ ì‹ ë¢°ì„± í…ŒìŠ¤íŠ¸ ê³„ì‚°**
- **Weibull ë¶„í¬**: ì œí’ˆ ìˆ˜ëª… ì˜ˆì¸¡ì— ê°€ì¥ ì í•©í•œ í†µê³„ ë¶„í¬ ì‚¬ìš©
- **Test Time ê³µì‹**: ìˆ˜í•™ì ìœ¼ë¡œ ê²€ì¦ëœ ê³µì‹ìœ¼ë¡œ ì •í™•í•œ í…ŒìŠ¤íŠ¸ ì‹œê°„ ë„ì¶œ
- **Anderson-Darling ê²€ì •**: ë¶„í¬ì˜ ê¼¬ë¦¬ ë¶€ë¶„ì— ë¯¼ê°í•œ ìµœê°•ë ¥ ì í•©ë„ ê²€ì •

**3. ì§€ëŠ¥í˜• ë² íƒ€ ê°’ ê²€ìƒ‰**
- **39ê°œ ì»´í¬ë„ŒíŠ¸**: ì‹¤ì œ ì‚°ì—… í‘œì¤€ ë° ì—°êµ¬ ë°ì´í„° ê¸°ë°˜
- **ë‹¤ì¤‘ ì†ŒìŠ¤**: ë°ì´í„°ë² ì´ìŠ¤ + OpenAI + ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
- **ì‹ ë¢°ë„ ë“±ê¸‰**: high/mediumìœ¼ë¡œ ë°ì´í„° í’ˆì§ˆ êµ¬ë¶„

**4. ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© ì‹œìŠ¤í…œ**
- **ë¹„ë™ê¸° ì²˜ë¦¬**: FastAPI Background Tasksë¡œ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬
- **í´ë§ ì‹œìŠ¤í…œ**: 10ì´ˆ ê°„ê²©ìœ¼ë¡œ ì§„í–‰ìƒí™© ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
- **ì‚¬ìš©ì ê²½í—˜**: 25ì´ˆ ëŒ€ê¸° â†’ ì¦‰ì‹œ ì‘ë‹µ + ì‹¤ì‹œê°„ ì§„í–‰ìƒí™©

**5. Excel MCP í†µí•©**
- **7ê°œ ì‹œíŠ¸**: ìš”ì•½ëŒ€ì‹œë³´ë“œë¶€í„° ì‹œìŠ¤í…œì •ë³´ê¹Œì§€ ì²´ê³„ì  êµ¬ì„±
- **ì „ë¬¸ ì°¨íŠ¸**: ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ìƒ‰ìƒ í…Œë§ˆ ë° ìë™ í¬ë§·íŒ…
- **ìë™í™”**: ë°ì´í„° ì—…ë¡œë“œë¶€í„° ë¦¬í¬íŠ¸ ìƒì„±ê¹Œì§€ ì „ ê³¼ì • ìë™í™”

### ğŸ’¡ **ê¸°ìˆ  ì„ íƒì˜ ì´ìœ **

**FastAPI**: 100ë§Œ í–‰ ë°ì´í„° ë¶„ì„ ì¤‘ì—ë„ ë‹¤ë¥¸ ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬ ê°€ëŠ¥
**Pandas + NumPy**: C ë ˆë²¨ ìµœì í™”ë¡œ ìˆœìˆ˜ Python ëŒ€ë¹„ 100ë°° ë¹ ë¥¸ ì²˜ë¦¬
**Excel MCP**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì²­í‚¹ ì „ëµ
**Weibull ë¶„í¬**: ì œí’ˆ ìˆ˜ëª… ì˜ˆì¸¡ì— ê°€ì¥ ì í•©í•œ í†µê³„ì  ë°©ë²•ë¡ 
**Anderson-Darling**: ë¶„í¬ì˜ ê·¹ë‹¨ê°’ì— ë¯¼ê°í•œ ìµœê°•ë ¥ ì í•©ë„ ê²€ì •
**í´ë§**: êµ¬í˜„ ê°„ë‹¨, ëª¨ë“  ë¸Œë¼ìš°ì € ì§€ì›, ì•ˆì •ì ì¸ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸

ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¨ìˆœí•œ ë¶„ì„ ë„êµ¬ë¥¼ ë„˜ì–´ì„œ, **ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ í”Œë«í¼**ìœ¼ë¡œì„œì˜ ì™„ì„±ë„ë¥¼ ë³´ì—¬ì£¼ë©°, ë©´ì ‘ì—ì„œ **ê¸°ìˆ ì  ì—­ëŸ‰ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥**ì„ íš¨ê³¼ì ìœ¼ë¡œ ì–´í•„í•  ìˆ˜ ìˆëŠ” í¬íŠ¸í´ë¦¬ì˜¤ì…ë‹ˆë‹¤.

**ë©´ì ‘ ëŒ€ë¹„ ê°•ì :**
- **ëŒ€ìš©ëŸ‰ ë°ì´í„° ê¸°ë°˜ ìë™ ì‹ ë¢°ì„± í…ŒìŠ¤íŠ¸ ê³„ì‚° ëŠ¥ë ¥**
- **Excel MCPë¥¼ í™œìš©í•œ ì „ë¬¸ì ì¸ í†µê³„ ë¶„ì„ ë° ì°¨íŠ¸ ìƒì„±**
- **ë‹¤ì¤‘ ì†ŒìŠ¤ ë² íƒ€ ê°’ ê²€ìƒ‰ ë° ê²€ì¦ ì‹œìŠ¤í…œ êµ¬í˜„**
- **Weibull ë¶„í¬ ì í•©ë„ ê²€ì • ë° ìˆ˜ëª… ì˜ˆì¸¡ ëª¨ë¸ë§**
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ê²½í—˜ ë° ìµœì í™” ëŠ¥ë ¥
- FastAPI ë¹„ë™ê¸° ì²˜ë¦¬ ë° ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… êµ¬í˜„
- Excel MCP í†µí•© ë° ìë™í™”ëœ ë¦¬í¬íŠ¸ ìƒì„±
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì„±ëŠ¥ ìµœì í™”
- í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ ì„¤ê³„

ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¨ìˆœí•œ ë¶„ì„ ë„êµ¬ë¥¼ ë„˜ì–´ì„œ, ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ í”Œë«í¼ìœ¼ë¡œì„œì˜ ì™„ì„±ë„ë¥¼ ë³´ì—¬ì£¼ë©°, ë©´ì ‘ì—ì„œ ê¸°ìˆ ì  ì—­ëŸ‰ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ ì–´í•„í•  ìˆ˜ ìˆëŠ” í¬íŠ¸í´ë¦¬ì˜¤ì…ë‹ˆë‹¤.


